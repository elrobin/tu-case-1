\documentclass[]{elsarticle} %review=doublespace preprint=single 5p=2 column
%%% Begin My package additions %%%%%%%%%%%%%%%%%%%
\usepackage[hyphens]{url}



\usepackage{lineno} % add
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\biboptions{sort&compress} % For natbib
\usepackage{graphicx}
\usepackage{booktabs} % book-quality tables
%%%%%%%%%%%%%%%% end my additions to header

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \usepackage{fontspec}
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\bibliographystyle{elsarticle-harv}
\usepackage{longtable}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={Unveiling the ecosystem of science: Towards an integrative valuation model of the many roles of scientists},
            colorlinks=false,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls

\setcounter{secnumdepth}{0}
% Pandoc toggle for numbering sections (defaults to be off)
\setcounter{secnumdepth}{0}
% Pandoc header



\begin{document}
\begin{frontmatter}

  \title{Unveiling the ecosystem of science: Towards an integrative valuation
model of the many roles of scientists}
    \author[a]{Nicolas Robinson-Garcia\corref{c1}}
   \ead{N.Robinson@tudelft.nl} 
   \cortext[c1]{Corresponding author}
    \author[b]{Rodrigo Costas}
  
  
    \author[b]{Thed N. van Leeuwen}
  
  
    \author[a]{Tina Nane}
  
  
      \address[a]{Applied Mathematics (DIAM), TU Delft, Delft, Netherlands}
    \address[b]{CWTS, Leiden University, Leiden, Netherlands}
  
  \begin{abstract}
  There is increasing evidence on the misuse and abuse of quantitative
  indicators in the current scientific reward system. Alternatively, more
  qualitative approaches, use of case studies or the design of indicators
  more sensitive to societal and scientific needs have been suggested. In
  this article we analyze the bases of such criticisms and motivations for
  changing the reward system by focusing on the assessment of individuals.
  We explore alternative models proposed or in use and identify common
  characteristics. Based on this we propose a valuation model by which we
  can systematically organize and prioritize performative aspects of
  scientists and consider other factors which may affect or might relevant
  for research policy. We finally test our model in a series of case
  studies based on six academic units.
  \end{abstract}
  
 \end{frontmatter}

\hypertarget{introduction}{%
\section{1. Introduction}\label{introduction}}

The ecosystem of science is defined as a system with interconnected
entities integrated in a larger social system with which a bidirectional
influence is exerted (Fortunato et al. 2018). Scientists, as drivers of
the research enterprise, are immersed in an increasingly diverse set of
tasks and activities with the purpose of producing, communicating and
transferring knowledge to society. This involves a series of skills
which go beyond their intellectual or technical capabilities (e.g.,
negotiation skills, communication skills, social engagement). The
introduction of national and supranational research evaluation systems
(Hicks 2012) carved the path to introducing measures of assessment in
the hope that they would help monitor and maximize such research
efforts. While peer review has traditionally been the main mechanism of
quality control (Bornmann 2011), there has been an increasing use of
bibliometric indicators. According to Gläser et al. (2002), this is due
to the fact that,

\begin{quote}
``{[}b{]}y applying quantitative performance indicators, actors in
science can be compared according to their performance more or less
independent of peers' judgments, and science policy can reach
conclusions seemingly independent of the scientific community to which
an actor belongs'' (pp.~29).
\end{quote}

An overemphasis on quantitative and specifically, bibliometric
indicators, has led to a situation in which academic careers are
assessed and rewarded relying solely on individuals' capacity to publish
highly cited research articles in highly ranked journals (McKiernan et
al. 2019; Wouters 2014). This unidimensional view of the research
enterprise has been harshely criticized (DORA 2014; Hicks et al. 2015;
Wilsdon et al. 2015), arguing mostly but not exclusively, on the
methodological and conceptual limitations they have when assessing
individuals. But there are more profound and serious effects derived
from current research evaluation schemes.

First, the focus on publications may lead to a task reduction, where
scientists neglect those types of work which are not recognized (Rijcke
et al. 2016). As consequence, there is a goal misplacement as the
researcher's efforts go into gaining higher scores in the measures
instead of pursuing their own research agenda. Second, quantitative
indicators are not always adequately used and introduced in research
evaluation schemes (Ràfols et al. 2016), which means that seemingly
`egalitarian' criteria can greatly hamper researchers from certain
fields or specific profiles (Gläser and Laudel 2007). Also, because such
indicators can be gamed (Fister, Fister, and Perc 2016), counteracting
rules to avoid misbehaviours can be even more harming (Robinson-Garcia
and Amat 2018). Third the focus on publishing in journals with a high
impact factor in tenure and promotion (McKiernan et al. 2019) leads to
systematic biases on the type of scientific knowledge produced. Rafols
et al. (2012) demonstrated systematic suppressing of interdisciplinary
research when using journal-based indicators for research evaluation.
Piñeiro and Hicks (2015) showed that, in the case of Spanish Sociology,
policies promoting publication in high impact journals indexed in the
Web of Science would penalize locally-oriented research. Chavarro, Tang,
and Ràfols (2017) reported that non-mainstream journals, which play an
important role in national science systems, are negatively affected by
these policies.

Finally, because a single set of criteria is defined for all scholars,
research evaluation schemes tend to promote a notion of the `excellent
scientist' who is capable of outperforming in all facets (Olmos-Peñuela,
Benneworth, and Castro-Martínez 2016), threatening the diversity of
scientific profiles researchers needed in the science ecosystem (Gläser
et al. 2002; Woolley and Robinson-Garcia 2017).

This article proposes an alternative model for evaluating scientists'
performance. This approach balances between a conceptually-informed
framework and a methodologically viable operationalization. We first
provide evidences on the specific aspects that are being negatively
affected by research evaluation schemes by reviewing previous empirical
work. After reviewing the different proposals made in the literature, we
propose a set of five performative dimensions which consider as
policy-relevant when conducting research assessment of individuals. A
key aspect of the model has to do with the networked nature of
scientific work and hence, the heterogeneity of research profiles
developed. Hence, how research trajectories develop and understanding
how specialization on specific roles might affect such categories is a
key point for our model. Also external factors affecting individuals'
performance along with effects of evaluation on personal features such
as gender, nationality or age, are considered as they can be directly or
indirectly affected by research policies and evaluation schemes. The
model is implemented in a multiple-case study of six organisational
subunits (i.e., departments, laboratories) from two Dutch universities.
This work contributes to existing research on the scientific workforce
and research careers in an inefficient evaluative context (Hammarfelt
and Rushforth 2017) which threatens diversity of scientific profiles,
and hence of outputs and impacts (Olmos-Peñuela, Benneworth, and
Castro-Martínez 2016; Woolley and Robinson-Garcia 2017).

\hypertarget{effects-of-evaluation-on-research-careers}{%
\section{2. Effects of evaluation on research
careers}\label{effects-of-evaluation-on-research-careers}}

\textbf{Claim 2: Publications offer a partial view of researchers'
outcomes.}

\begin{itemize}
\tightlist
\item
  What do researchers do?
\item
  How they organize their time?
\item
  Which are their outcomes?
\end{itemize}

\textbf{Claim 3: Invisible profiles are becoming more necessary than
ever but are being kicked out of the system.}

\begin{itemize}
\tightlist
\item
  How do they distribute tasks?
\item
  How do they negotiate authorship?
\item
  How do they allocate credit and prestige
\item
  Supporting evidence: Milojevic et al.~PNAS (2018) publication.
\end{itemize}

\hypertarget{lit-review}{%
\section{2. Lit review}\label{lit-review}}

\hypertarget{stratification-and-diversity-of-scientific-profiles}{%
\subsection{Stratification and diversity of scientific
profiles}\label{stratification-and-diversity-of-scientific-profiles}}

Examples of dimensions can be given from the book by Bastow, Tinkler \&
Dunleavy (2014)

Bozeman, Dietz \& Gaughan (2001) present their evaluation model at the
individual level as follows:

\begin{itemize}
\tightlist
\item
  Internal resources: cognitive skills (this can be criticized as it is
  impossible to operationalize as they present it i.e., ability to
  synthesize), S\&T knowledge and context skills (learnt through
  experience). The authors indicate that each resource may have n
  dimensions.
\item
  S\&T Capital: Which has to do with the network of scientists and the
  intrinsic value they have as well as the role the individual plays in
  such network
\item
  S\&T Human Capital and Life Cycles: The authors recognize that
  researchers' profile will be different at different stages of their
  career.
\item
  Corley et al (2017) introduce a cultural dimension to the model which
  refers to variables such as gender, nationality, race, discipline or
  socio-economic status.
\end{itemize}

ACUMEN presents a portfolio, a kind of CV format designed for assessing
individual performance. It combines qualitative and quantitative
information. It offers space for a narrative where an individual tells
her own story. It then distinguishes between three aspects of an
academic's career: expertise (methods, areas of theory, etc.), outputs
(publications, patents, etc.) and impacts (citations, awards, etc.).
Furthermore, it includes an individual's age. For these three aspects it
includes quantitative indicators. The perspective here is that
individuals report their CV and the ACUMEN portfolio basically
structures and offers recommendations on how this should be provided.
Other than that it does not give clear indications on how the assessment
should be performed, it seems to rely on experts' judgment.

Look into Whitley

Look into Evaluative Inquiry

\hypertarget{effects-of-evaluation-on-research-careers-some-evidences}{%
\subsubsection{Effects of evaluation on research careers: Some
evidences}\label{effects-of-evaluation-on-research-careers-some-evidences}}

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.29\columnwidth}\raggedright
Critique\strut
\end{minipage} & \begin{minipage}[b]{0.32\columnwidth}\raggedright
Evidences\strut
\end{minipage} & \begin{minipage}[b]{0.29\columnwidth}\raggedright
Reference\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.29\columnwidth}\raggedright
Abuse of JIF in evaluations\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright
Documentation from 129 univs. and 381 academic units in US and
Canada\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright
McKiernan et al., 2019\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
Misalignment between societal needs and research\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright
Desktop research and expert panel workshop\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright
Moher et al., 2018\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.29\columnwidth}\raggedright
Bibliometric indicators pervert scientific enterprise\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright
Policy experience\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright
Benedictus (2016), Edwards (2017)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Authors like Moher et al.~(2018) or Nosek (2015) refer to research
integrity, and in the case of the latter, refer to conflict of interest
of researchers as they might be interested on publication even if
results are not accurate. This would lead to Ioannidis' famous paper on
the reproducibility crisis and false results.

Abramo, G., D'Angelo, C. A., \& Rosati, F. (2015). The determinants of
academic career advancement: Evidence from Italy. Science and Public
Policy, 42(6), 761-774. https://doi.org/10.1093/scipol/scu086

Luukkonen, T., \& Thomas, D. A. (2016). The `Negotiated Space' of
University Researchers' Pursuit of a Research Agenda. Minerva, 54(1),
99-127. https://doi.org/10.1007/s11024-016-9291-z

\hypertarget{career-trajectories}{%
\subsubsection{Career trajectories}\label{career-trajectories}}

Stephan \& Levin -\textgreater{} In terms of productivity peaks and
decline

Laudel, G., Bielick, J., \& Gläser, J. (2018). `Ultimately the question
always is: ``What do I have to do to do it right?''\,' Scripts as
explanatory factors of career decisions. Human Relations,
0018726718786550. https://doi.org/10.1177/0018726718786550

\hypertarget{valuation-models-of-scientific-activity}{%
\subsubsection{Valuation models of scientific
activity}\label{valuation-models-of-scientific-activity}}

I have changed the name of the section to valuation so that it alignes
with the ISSI poster. This means that the variables considered in the
table should also be modified and reflect on the aspects valued by each
of these models.

Interesting the model presented by Boyer (1990) and used in the paper by
Herman \& Nicholas (2019) published in El profesional de la información.
Furthermore, should consider the term \emph{facet} instead of referring
to \emph{dimensions}, it might be more accurate.

\begin{longtable}[]{@{}llll@{}}
\toprule
\begin{minipage}[b]{0.24\columnwidth}\raggedright
Evaluation model\strut
\end{minipage} & \begin{minipage}[b]{0.23\columnwidth}\raggedright
Output/outcome\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
Unit of analysis\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedright
References\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.24\columnwidth}\raggedright
Bibliometric assessment\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
Production and impact\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Scalable\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.24\columnwidth}\raggedright
Economic analysis\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.24\columnwidth}\raggedright
Knowledge value alliances\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Communities of scholars (e.g., labs)\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Bozeman \& Rogers\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.24\columnwidth}\raggedright
Research portfolios\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
Journal articles?\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Wallace \& Rafols, 2015\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.24\columnwidth}\raggedright
Productive interactions\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
Process-oriented\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Research projects\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Spaape \& van Drooge, 2011\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.24\columnwidth}\raggedright
S\&T Human Capital\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Scalable\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Bozeman, Dietz \& Gaughan, 2001\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{methodological-framework}{%
\section{3. Methodological framework}\label{methodological-framework}}

\hypertarget{data}{%
\subsection{Data}\label{data}}

To test the reliability of the model, we selected a technical university
and a general university. Furthermore, these subunits belong to three
different fields (Medical Sciences, Engineering Sciences and Social
Sciences), a

\hypertarget{evaluative-dimensions}{%
\subsection{Evaluative dimensions}\label{evaluative-dimensions}}

\hypertarget{scientific-engagement}{%
\subsubsection{Scientific engagement}\label{scientific-engagement}}

Collaboration ties and diversity (number of unique collaborators and
intensity), position in network, (co-authorship, acknowledgment, etc.),
strength of tie?, interdisciplinarity, application of research, member
of committees, reviewer, etc.

Social engagement

Non-academic collaboration ties (either through publications or not
i.e., reference patterns), some altmetric indicators (policy briefs but
also maybe twitter classes? Or potentially Ed's ABC score), spin-offs,

Capacity-building

Productivity, leadership, independence, scientific impact, funding

Trajectory/Background?

Geographic mobility, cognitive mobility, sectoral mobility (These last
three could be seen not as attributes to the researcher but their
capacity to work with diverse people), career status

Research practices (Cross-sectoral)

OA publications, data sharing, outreach (e.g., The Conversation,
blogging, tweeting), publication of working papers, proceedings,
mentoring

Some references

Alperin, J. P., Nieves, C. M., Schimanski, L., Fischman, G. E., Niles,
M. T., \& McKiernan, E. C. (2018). How significant are the public
dimensions of faculty work in review, promotion, and tenure documents?
Recuperado de https://hcommons.org/deposits/item/hc:21015/

July 3rd, researchers, 2018\textbar{}Early career, education, H.,
science, O., evaluation, R., \& Comment, R. policy\textbar{}1. (2018,
julio 3). Making research evaluation processes in Europe more
transparent. Recuperado 20 de febrero de 2019, de
https://blogs.lse.ac.uk/impactofsocialsciences/2018/07/03/making-research-evaluation-processes-in-europe-more-transparent/

Schimanski, L. A., \& Alperin, J. P. (2018). The evaluation of
scholarship in academic promotion and tenure processes: Past, present,
and future. F1000Research, 7, 1605.
https://doi.org/10.12688/f1000research.16493.1

\hypertarget{confounding-effects}{%
\subsubsection{Confounding effects}\label{confounding-effects}}

\hypertarget{personal-features}{%
\subsubsection{Personal features}\label{personal-features}}

Order dimensions from time independent to dependent. Features within
dimensions

\hypertarget{results}{%
\section{4. Results}\label{results}}

\begin{itemize}
\tightlist
\item
  Showcase dimensions for research teams or labs -\textgreater{}
  Internal organization and division of labor
\item
  Showcase dimensions life cycles -\textgreater{} Different stages in
  career
\item
  Attribution Plos One -\textgreater{} Scientific engagement
\item
  Differences on profiles by fields.
\item
  Agencies
\end{itemize}

\pagebreak

\hypertarget{codebook}{%
\section{Codebook}\label{codebook}}

Here I describe the selection of case studies and the data retrieval
process and description of sources. The purpose of this is to show that
1) there are indeed a variety of different profiles, 2) these profiles
co-exist and complement each other, 3) the diversity and typologies of
profiles is field dependent, 4) personal features are key to understand
this diversity. Here we emphasize two specific personal features: age
and gender. Some of the research questions that could be answered
descriptively are the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Is there team science?}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \emph{Are these teams stable over time?} Some data that could be
  retrieved from WoS
\end{enumerate}

\begin{verbatim}
-   Cluster_id
-   All classic bibliometric indicators
-   Number of collaborators from same institution
-   Number of external collaborators
-   Number of collaborators from same institution by publication
-   Number of external collaborators by publication
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \emph{Is there activity visible through co-authorship?} Check groups
  identified with manual checking in the web and maybe interviews
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \emph{Do research teams operate in a coordinated way?} Here it would
  be interesting to understand dependence relationship. Nederhof \& van
  Raan (1993) refer to the star effects as what happens when a PI
  retires and the research group disappears. Here we should go beyond
  bibliometrics and see if there is someone in charge of the funding,
  someone of hiring and finding opportunities, someone who is more of a
  public face, etc. Also it would be interesting to use network analysis
  to determine authorities, hubs, etc. and contrast with their judgment.
  Some variables from WoS and interivews plus manually cheking:
  authorship position (WoS); acknowledgments data (WoS); clusters from
  Ludo's subject classification to identify areas of specialization per
  subject (WoS); social media activity; Google Scholar data.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \emph{Do they have a common research agenda?}
\item
  \emph{How is this agenda established?}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \emph{How does team science affect individual trajectories?}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \emph{How is credit shared?}
\item
  \emph{What is the relation between the role exerted and academic
  status?} A cohort analysis?
\item
  \emph{How is continuity of supporting scientists ensured?} Probably
  also from interviews. How do scholars change from institution or are
  maintained if they are not able to `make the next step'.
\end{enumerate}

\hypertarget{selection-of-case-studies}{%
\subsection{Selection of case studies}\label{selection-of-case-studies}}

The identification of research groups is done bibliometrically and based
on Web of Science publications. For this I have selected all
publications between 2008 and 2017 by LUMC, Leiden University or TU
Delft. The following table includes some descriptives. Here I must note
that researchers belonging to institutions are not based on the specific
affiliation linkage of docs (which uses the Leiden Ranking affiliation
already cleaned up), but based on \texttt{cluster\_id} with either of
the three institutions as their main or alternative address. This should
be checked to see if there is a way to link to the \texttt{cluster\_id}
organizations to the cleaned affiliations from Leiden Ranking. I had to
clean up this data myself. In any case this should not be a concern for
the selection of case studies.

\begin{longtable}[]{@{}lccc@{}}
\toprule
& TU Delft & Leiden Univ & LUMC\tabularnewline
\midrule
\endhead
Publications & 24,233 & 49,149 & 3,188\tabularnewline
Researchers & 9,975 & 14,116 & 279\tabularnewline
Collaborators & 34,409 & 117,307 & 14,153\tabularnewline
Mean au/p & 4.7 & 9.6 & 10.1\tabularnewline
Median au/p & 4 & 6 & 8\tabularnewline
Sd au/p & 5.4 & 31.5 & 18.7\tabularnewline
\bottomrule
\end{longtable}

The next figure shows the distribution of papers based on the number of
authors by paper (A) and the thematic profile of each of the three
institutions. Leiden University is the largest of the three institutions
with a more comprehensive portfolio, although mostly focues on
Biomedical Sciences and Social Sciences. This focus on biomedical
sciences is obviously more noticeable in the case of LUMC, although it
still has some pubications in fields of the social sciences, mostly
related with Public Health. Finally, TU Delft shows a profile focused on
Phisics, Engineering and Mathematics. While there might be an overlap
between LUMC and Leiden University, the high preponderance of biomedical
literature might also be due to a close relation between these
universities.

\includegraphics[width=2.97in]{figs/histogram-profiles}

Six case studies will be selected. Three for each university and two by
field. The purpose of this is not only to identify differences by
discipline but also by institutional type. The fields are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Physics and Engineering
\item
  Social Sciences and Humanities
\item
  Biomedical Sciences
\end{enumerate}

Following I include the collaboration networks for each university and
field. I have included a threshold of at least 10 publications by
\texttt{cluster\_id}, filtered by the giant component and calculated the
betweenness centrality of each node. I have selected as seed researcher
the one with the highest centrality.

\hypertarget{physics-engineering}{%
\subsubsection{Physics \& Engineering}\label{physics-engineering}}

\hypertarget{tu-delft}{%
\paragraph{1. TU Delft}\label{tu-delft}}

\includegraphics[width=3.41in]{figs/tu_phys_betweenness}

\emph{Notes:}

\begin{itemize}
\tightlist
\item
  1260 nodes (21.9\% visible); 4702 edges (27.1\% visible).
\item
  \texttt{cluster\_id} with highest betweenness = 33800547; Betweenness
  centrality: 0.11; Total publications = 159; Age = 32
\item
  Name: Frans D. Tichelaar; First year: 1986; Last year: 2018
\item
  PURE:
  https://pure.tudelft.nl/portal/en/persons/fd-tichelaar(56299c58-b6ec-478b-b188-b8744b69d954).html
\item
  Institution: http://nchrem.nl/people/dr-ir-f-d-tichelaar-frans/
\end{itemize}

\hypertarget{leiden-univ}{%
\paragraph{2. Leiden Univ}\label{leiden-univ}}

\includegraphics[width=3.41in]{figs/lu_phys_betweenness}

\emph{Notes:}

\begin{itemize}
\tightlist
\item
  765 nodes (35.1\% visible); 3409 edges (40.6\% visible).
\item
  \texttt{cluster\_id} with highest betweenness = 25501410; Betweenness
  centrality: 0.23; Total publications = 590; Age = 38
\item
  Name: Ewine F. van Dishoeck; First year: 1980; Last year: 2018
\item
  Institution:
  https://local.strw.leidenuniv.nl/people/touchscreen2/persinline.php?id=16
\item
  Personal website:
  https://home.strw.leidenuniv.nl/\textasciitilde{}ewine/
\end{itemize}

\hypertarget{biomedical-and-health-sciences}{%
\subsubsection{Biomedical and Health
Sciences}\label{biomedical-and-health-sciences}}

\hypertarget{tu-delft-1}{%
\paragraph{1. TU Delft}\label{tu-delft-1}}

\includegraphics[width=3.41in]{figs/tu_bio_betweenness}

\emph{Notes:}

\begin{itemize}
\tightlist
\item
  214 nodes (18.9\% visible); 615 edges (25.49\% visible).
\item
  \texttt{cluster\_id} with highest betweenness = 43204348; Betweenness
  centrality: 0.50; Total publications = 341; Age = 31
\item
  Name: Harrie H. Weinans; First year: 1987; Last year: 2018
\item
  Google Profile:
  https://scholar.google.com/citations?user=di4NUp8AAAAJ\&hl=en
\item
  PURE:
  https://pure.tudelft.nl/portal/en/persons/hh-weinans(f31bd75b-1863-4202-b64b-7356538284a7)/publications.html
\item
  Co-affiliated to UMC Utrecht and TU Delft.
\end{itemize}

\hypertarget{leiden-univ-1}{%
\paragraph{2. Leiden Univ}\label{leiden-univ-1}}

\includegraphics[width=3.41in]{figs/lu_bio_betweenness}

\emph{Notes:}

\begin{itemize}
\tightlist
\item
  Due to the density of the network the selected node can scarcely be
  seen.
\item
  3304 nodes (38.8\% visible); 43647 edges (59.6\% visible).
\item
  \texttt{cluster\_id} with highest betweenness = 19936939; Betweenness
  centrality: 0.47; Total publications = 185; Age = 27
\item
  Name: Ron Wolterbeek; First year: 1991; Last year: 2018
\item
  Institution: https://www.lumc.nl/org/bds/medewerkers/rwolterbeek
\item
  Affiliated to LUMC.
\end{itemize}

\hypertarget{social-sciences-and-humanities}{%
\subsubsection{Social Sciences and
Humanities}\label{social-sciences-and-humanities}}

\hypertarget{tu-delft-2}{%
\paragraph{1. TU Delft}\label{tu-delft-2}}

\includegraphics[width=3.41in]{figs/tu_soc_betweenness}

\emph{Notes:}

\begin{itemize}
\tightlist
\item
  151 nodes (12.6\% visible); 281 edges (15.8\% visible).
\item
  \texttt{cluster\_id} with highest betweenness = 12392841; Betweenness
  centrality: 0.41; Total publications = 134; Age = 18
\item
  Name: Bert van Wee; First year: 1999; Last year: 2018
\item
  Google Profile:
  https://scholar.google.es/citations?user=dYUiqMYAAAAJ\&hl=en
\item
  Institution:
  https://www.tudelft.nl/en/tpm/about-the-faculty/departments/engineering-systems-and-services/people/full-professors/profdr-gp-bert-van-wee/
\end{itemize}

\hypertarget{leiden-univ-2}{%
\paragraph{2. Leiden Univ}\label{leiden-univ-2}}

\includegraphics[width=3.41in]{figs/lu_soc_betweenness}

\emph{Notes:}

In this case, the selection of the seed researcher was not based on
network indicator. The network above has the OpenOrd layout (instead of
Yi ) and K-Core=1 group. The main issue here is that this field is
largely populated by biomedical scientists and psychologists and
psychiatrists, fields which are not good representations of Social
Sciences and Humanities. What I have done is looked at those pairs of
scholars with the highest shares of co-authored papers and go down the
list until I found someone who was not from these fields nor from CWTS
(Ludo and Nees are the third pair with more co-authored papers)

\begin{itemize}
\tightlist
\item
  478 nodes (26.5\% visible); 1294 edges (43.1\% visible).
\item
  \texttt{cluster\_id} selected = 36871407; Betweenness centrality:
  0.00; Total publications = 78; Age = 18
\item
  Name: Judi Mesman; First year: 2000; Last year: 2018
\item
  Institution:
  https://www.universiteitleiden.nl/en/staffmembers/judi-mesman/publications\#tab-1
\item
  Lab1: http://www.diversityinparenting.nl/
\item
  Lab2: https://www.societalchallengeslab.com/
\end{itemize}

\hypertarget{expansion-from-seed-to-complete-team}{%
\subsection{Expansion from seed to complete
team}\label{expansion-from-seed-to-complete-team}}

Based on the six individuals selected in the first phase. I know search
for their complete research team. The data retrieval process started on
March, 2019. Here I include for each case how I have proceeded.

\hypertarget{physics-engineering---tu-delft}{%
\subsubsection{Physics \& Engineering - TU
Delft}\label{physics-engineering---tu-delft}}

Dr.~Ir. F.D. Tichelaar belongs to the National Centre for High
Resolution Electron Microscopy. According to its website, he is not the
head of the institute which is formed by 9 researchers (5 staff and 4
researchers and post docs)

\hypertarget{physics-engineering---leiden-univ}{%
\subsubsection{Physics \& Engineering - Leiden
Univ}\label{physics-engineering---leiden-univ}}

Prof.~Ewine van Dishoeck belongs to the Leiden Observatory. According to
its website, there are 179 workers: 33 are staff members, 50 postdocs,
63 PhD students and 26 supporting staff.

\hypertarget{biomedical-sciences---tu-delft}{%
\subsubsection{Biomedical Sciences - TU
Delft}\label{biomedical-sciences---tu-delft}}

Harrie H. Weinans is associate professor at UMC Utrecht in the
department of Orthopaedics and Professor at TU Delft at the
Biomechanical Engineering department. Here information is gathered from
TU Delft. He is a parttime professor. Here I will not include the whole
department, but only researchers working on the Biomaterials \& Tissue
Biomechanics group. Only supporting staff assigned to this group is
included.

\hypertarget{biomedical-sciences---leiden-university}{%
\subsubsection{Biomedical Sciences - Leiden
University}\label{biomedical-sciences---leiden-university}}

Ron Wolterbeek is first-line consultant in the area of Medical
Statistics at LUMC. I could not find him actually in the staff page, so
decided to look into the staff included there. There is not much about
him in the Internet other than his publications.

\hypertarget{social-sciences-and-humanities---tu-delft}{%
\subsubsection{Social Sciences and Humanities - TU
Delft}\label{social-sciences-and-humanities---tu-delft}}

Bert van Wee is professor in Transport Policy at the department of
Engineering Systems and Services. In this case I do not find anything as
research teams or groups and hence I am including the whole department.

\hypertarget{social-sciences-and-humanities---leiden-univ}{%
\subsubsection{Social Sciences and Humanities - Leiden
Univ}\label{social-sciences-and-humanities---leiden-univ}}

Judi Mesman is dean of Leiden University College The Hague and professor
of the interdisciplinary study of societal challenges. She directs the
Societal Challenges Lab which is part of both the Faculty of Governance
and global Affairs and the Faculty of Social Sciences at Leiden
University. This case study is based on her lab.

\hypertarget{data-sources}{%
\subsection{Data sources}\label{data-sources}}

Data sources are selected based on dimensions from the \emph{valuation
model}. Following I include the main ones selected:

\begin{itemize}
\item
  \textbf{CWTS-Web of Science.} Publication and citation indicators are
  retrieved since 1980 or first publication to 2018 by matching
  individual to \texttt{cluster\_id} following the author name
  disambiguation developed by Caron \& van Eck (2014).
\item
\end{itemize}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-bornmannScientificPeerReview2011}{}%
Bornmann, Lutz. 2011. ``Scientific Peer Review.'' \emph{Annual Review of
Information Science and Technology} 45 (1): 197--245.
\url{http://onlinelibrary.wiley.com/doi/10.1002/aris.2011.1440450112/full}.

\leavevmode\hypertarget{ref-chavarroWhyResearchersPublish2017}{}%
Chavarro, Diego, Puay Tang, and Ismael Ràfols. 2017. ``Why Researchers
Publish in Non-Mainstream Journals: Training, Knowledge Bridging, and
Gap Filling.'' \emph{Research Policy} 46 (9): 1666--80.
\url{https://doi.org/10.1016/j.respol.2017.08.002}.

\leavevmode\hypertarget{ref-doraSanFranciscoDeclaration2014}{}%
DORA. 2014. ``San Francisco Declaration on Research Assessment.''
\url{https://sfdora.org/}.

\leavevmode\hypertarget{ref-fisterDiscoveryCitationCartels2016}{}%
Fister, Iztok Jr, Iztok Fister, and Matjaž Perc. 2016. ``Toward the
Discovery of Citation Cartels in Citation Networks.'' \emph{Frontiers in
Physics} 4. \url{https://doi.org/10.3389/fphy.2016.00049}.

\leavevmode\hypertarget{ref-fortunatoScienceScience2018}{}%
Fortunato, Santo, Carl T. Bergstrom, Katy Börner, James A. Evans, Dirk
Helbing, Stasa Milojevic, Alexander M. Petersen, et al. 2018. ``Science
of Science.'' \emph{Science} 359 (6379): eaao0185.
\url{https://doi.org/10.1126/science.aao0185}.

\leavevmode\hypertarget{ref-glaserEvaluationEvaluators2007}{}%
Gläser, Jochen, and Grit Laudel. 2007. ``Evaluation Without
Evaluators.'' In \emph{The Changing Governance of the Sciences: The
Advent of Research Evaluation Systems}, edited by Richard Whitley and
Jochen Gläser, 127--51. Sociology of the Sciences Yearbook. Dordrecht:
Springer Netherlands. \url{https://doi.org/10.1007/978-1-4020-6746-4_6}.

\leavevmode\hypertarget{ref-glaserImpactEvaluationbasedFunding2002}{}%
Gläser, Jochen, Grit Laudel, Sybille Hinze, and Linda Butler. 2002.
``Impact of Evaluation-Based Funding on the Production of Scientific
Knowledge: What to Worry About, and How to Find Out.'' \emph{Expertise
for the German Ministry for Education and Research} 31: 2002.

\leavevmode\hypertarget{ref-hammarfeltIndicatorsJudgmentDevices2017}{}%
Hammarfelt, Björn, and Alexander D. Rushforth. 2017. ``Indicators as
Judgment Devices: An Empirical Study of Citizen Bibliometrics in
Research Evaluation.'' \emph{Research Evaluation} 26 (3): 169--80.
\url{https://doi.org/10.1093/reseval/rvx018}.

\leavevmode\hypertarget{ref-hicksPerformancebasedUniversityResearch2012}{}%
Hicks, Diana. 2012. ``Performance-Based University Research Funding
Systems.'' \emph{Research Policy} 41 (2): 251--61.
\url{http://www.sciencedirect.com/science/article/pii/S0048733311001752}.

\leavevmode\hypertarget{ref-hicksLeidenManifestoResearch2015}{}%
Hicks, Diana, Paul Wouters, Ludo Waltman, Sarah de Rijcke, and Ismael
Rafols. 2015. ``The Leiden Manifesto for Research Metrics.''
\emph{Nature} 520 (7548): 429--31.
\url{https://doi.org/10.1038/520429a}.

\leavevmode\hypertarget{ref-mckiernanUseJournalImpact2019}{}%
McKiernan, Erin C., Lesley A. Schimanski, Carol Muñoz Nieves, Lisa
Matthias, Meredith T. Niles, and Juan Pablo Alperin. 2019. ``Use of the
Journal Impact Factor in Academic Review, Promotion, and Tenure
Evaluations.'' e27638v2. PeerJ Inc.
\url{https://doi.org/10.7287/peerj.preprints.27638v2}.

\leavevmode\hypertarget{ref-olmos-penuelaDoesItTake2016}{}%
Olmos-Peñuela, Julia, Paul Benneworth, and Elena Castro-Martínez. 2016.
``Does It Take Two to Tango? Factors Related to the Ease of Societal
Uptake of Scientific Knowledge.'' \emph{Science and Public Policy} 43
(6): 751--62. \url{https://doi.org/10.1093/scipol/scw016}.

\leavevmode\hypertarget{ref-pineiroReceptionSpanishSociology2015}{}%
Piñeiro, Carla López, and Diana Hicks. 2015. ``Reception of Spanish
Sociology by Domestic and Foreign Audiences Differs and Has Consequences
for Evaluation.'' \emph{Research Evaluation} 24 (1): 78--89.
\url{http://rev.oxfordjournals.org/content/24/1/78.short}.

\leavevmode\hypertarget{ref-rafolsHowJournalRankings2012}{}%
Rafols, Ismael, Loet Leydesdorff, Alice O'Hare, Paul Nightingale, and
Andy Stirling. 2012. ``How Journal Rankings Can Suppress
Interdisciplinary Research: A Comparison Between Innovation Studies and
Business \& Management.'' \emph{Research Policy}, Exploring the Emerging
Knowledge Base of 'The Knowledge Society', 41 (7): 1262--82.
\url{https://doi.org/10.1016/j.respol.2012.03.015}.

\leavevmode\hypertarget{ref-rafolsDominanceQuantitativeEvaluation2016}{}%
Ràfols, Ismael, Jordi Molas-Gallart, Diego Andrés Chavarro, and Nicolas
Robinson-Garcia. 2016. ``On the Dominance of Quantitative Evaluation in
`Peripheral' Countries: Auditing Research with Technologies of
Distance.'' SSRN Scholarly Paper ID 2818335. Rochester, NY: Social
Science Research Network.
\url{https://papers.ssrn.com/abstract=2818335}.

\leavevmode\hypertarget{ref-rijckeEvaluationPracticesEffects2016}{}%
Rijcke, Sarah de, Paul F. Wouters, Alex D. Rushforth, Thomas P.
Franssen, and Björn Hammarfelt. 2016. ``Evaluation Practices and Effects
of Indicator Use---a Literature Review.'' \emph{Research Evaluation} 25
(2): 161--69. \url{https://doi.org/10.1093/reseval/rvv038}.

\leavevmode\hypertarget{ref-robinson-garciaTieneSentidoLimitar2018}{}%
Robinson-Garcia, Nicolas, and Carlos B. Amat. 2018. ``¿Tiene Sentido
Limitar La Coautoría Científica? No Existe Inflación de Autores En
Ciencias Sociales Y Educación En España.'' \emph{Revista Española de
Documentación Científica} 41 (2): 201.
\url{https://doi.org/10.3989/redc.2018.2.1499}.

\leavevmode\hypertarget{ref-wilsdonMetricTideReport2015}{}%
Wilsdon, J., Liz Allen, Eleonora Belfiore, Philip Campbell, Stephen
Curry, Steven Hill, Richard Jones, et al. 2015. ``The Metric Tide:
Report of the Independent Review of the Role of Metrics in Research
Assessment and Management.'' HEFCE.
\url{http://doi.org/10.13140/RG.2.1.4929.1363}.

\leavevmode\hypertarget{ref-woolley2014REFResults2017}{}%
Woolley, Richard, and Nicolas Robinson-Garcia. 2017. ``The 2014 REF
Results Show Only a Very Weak Relationship Between Excellence in
Research and Achieving Societal Impact.'' \emph{Impact of Social
Sciences Blog}.
\url{https://blogs.lse.ac.uk/impactofsocialsciences/2017/07/19/what-do-the-2014-ref-results-tell-us-about-the-relationship-between-excellent-research-and-societal-impact/}.

\leavevmode\hypertarget{ref-woutersCitationCultureInfrastructure2014}{}%
Wouters, Paul. 2014. ``The Citation: From Culture to Infrastructure.''
In \emph{Beyond Bibliometrics: Harnessing Multidimensional Indicators of
Scholarly Impact}, edited by Blaise Cronin and Cassidy R. Sugimoto,
47--66. Cambridge, MA: MIT Press.


\end{document}


